{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 3s 0us/step\n",
      "x_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/12\n",
      "60000/60000 [==============================] - 130s 2ms/step - loss: 0.2853 - acc: 0.9138 - val_loss: 0.0695 - val_acc: 0.9774\n",
      "Epoch 2/12\n",
      "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0953 - acc: 0.9719 - val_loss: 0.0447 - val_acc: 0.9853\n",
      "Epoch 3/12\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0695 - acc: 0.9792 - val_loss: 0.0371 - val_acc: 0.9875\n",
      "Epoch 4/12\n",
      "60000/60000 [==============================] - 124s 2ms/step - loss: 0.0569 - acc: 0.9827 - val_loss: 0.0331 - val_acc: 0.9889\n",
      "Epoch 5/12\n",
      "60000/60000 [==============================] - 140s 2ms/step - loss: 0.0502 - acc: 0.9851 - val_loss: 0.0305 - val_acc: 0.9898\n",
      "Epoch 6/12\n",
      "60000/60000 [==============================] - 123s 2ms/step - loss: 0.0429 - acc: 0.9867 - val_loss: 0.0319 - val_acc: 0.9895\n",
      "Epoch 7/12\n",
      "60000/60000 [==============================] - 125s 2ms/step - loss: 0.0384 - acc: 0.9883 - val_loss: 0.0280 - val_acc: 0.9908\n",
      "Epoch 8/12\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0354 - acc: 0.9891 - val_loss: 0.0294 - val_acc: 0.9910\n",
      "Epoch 9/12\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0346 - acc: 0.9894 - val_loss: 0.0286 - val_acc: 0.9903\n",
      "Epoch 10/12\n",
      "60000/60000 [==============================] - 128s 2ms/step - loss: 0.0308 - acc: 0.9904 - val_loss: 0.0272 - val_acc: 0.9914\n",
      "Epoch 11/12\n",
      "60000/60000 [==============================] - 129s 2ms/step - loss: 0.0304 - acc: 0.9909 - val_loss: 0.0307 - val_acc: 0.9909\n",
      "Epoch 12/12\n",
      "60000/60000 [==============================] - 126s 2ms/step - loss: 0.0276 - acc: 0.9915 - val_loss: 0.0291 - val_acc: 0.9908\n",
      "Test loss: 0.029080516574144167\n",
      "Test accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "'''Trains a simple convnet on the MNIST dataset.\n",
    "Gets to 99.25% test accuracy after 12 epochs\n",
    "(there is still a lot of margin for parameter tuning).\n",
    "16 seconds per epoch on a GRID K520 GPU.\n",
    "'''\n",
    "\n",
    "from __future__ import print_function\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 12\n",
    "\n",
    "# input image dimensions\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "if K.image_data_format() == 'channels_first':\n",
    "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "    input_shape = (1, img_rows, img_cols)\n",
    "else:\n",
    "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "    input_shape = (img_rows, img_cols, 1)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, kernel_size=(3, 3),\n",
    "                 activation='relu',\n",
    "                 input_shape=input_shape))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "i = 150\n",
    "im = x_train[i, :, :, 0]\n",
    "\n",
    "plt.imshow(im)\n",
    "print(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"my_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
