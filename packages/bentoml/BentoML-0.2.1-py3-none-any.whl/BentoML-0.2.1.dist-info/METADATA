Metadata-Version: 2.1
Name: BentoML
Version: 0.2.1
Summary: An open framework for building, shipping and running machine learning services
Home-page: https://github.com/bentoml/BentoML
Author: atalaya.io
Author-email: contact@atalaya.io
License: UNKNOWN
Project-URL: Bug Reports, https://github.com/bentoml/BentoML/issues
Project-URL: Source Code, https://github.com/bentoml/BentoML
Project-URL: Gitter Chat Room, https://gitter.im/bentoml/BentoML
Platform: UNKNOWN
Classifier: Programming Language :: Python :: 2.7
Classifier: Programming Language :: Python :: 3.4
Classifier: Programming Language :: Python :: 3.5
Classifier: Programming Language :: Python :: 3.6
Classifier: Programming Language :: Python :: 3.7
Classifier: Programming Language :: Python :: Implementation :: CPython
Classifier: Programming Language :: Python :: Implementation :: PyPy
Classifier: License :: OSI Approved :: Apache Software License
Classifier: Operating System :: OS Independent
Requires-Python: >=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*
Description-Content-Type: text/markdown
Requires-Dist: ruamel.yaml (>=0.15.0)
Requires-Dist: numpy
Requires-Dist: flask
Requires-Dist: gunicorn
Requires-Dist: six
Requires-Dist: click
Requires-Dist: pandas
Requires-Dist: dill
Requires-Dist: prometheus-client
Requires-Dist: python-json-logger
Requires-Dist: boto3
Requires-Dist: pathlib2
Requires-Dist: requests
Requires-Dist: packaging
Requires-Dist: docker
Requires-Dist: configparser
Provides-Extra: all
Requires-Dist: ruamel.yaml (>=0.15.0) ; extra == 'all'
Requires-Dist: numpy ; extra == 'all'
Requires-Dist: flask ; extra == 'all'
Requires-Dist: gunicorn ; extra == 'all'
Requires-Dist: six ; extra == 'all'
Requires-Dist: click ; extra == 'all'
Requires-Dist: pandas ; extra == 'all'
Requires-Dist: dill ; extra == 'all'
Requires-Dist: prometheus-client ; extra == 'all'
Requires-Dist: python-json-logger ; extra == 'all'
Requires-Dist: boto3 ; extra == 'all'
Requires-Dist: pathlib2 ; extra == 'all'
Requires-Dist: requests ; extra == 'all'
Requires-Dist: packaging ; extra == 'all'
Requires-Dist: docker ; extra == 'all'
Requires-Dist: configparser ; extra == 'all'
Requires-Dist: pylint (==2.3.1) ; extra == 'all'
Requires-Dist: flake8 ; extra == 'all'
Requires-Dist: tox-conda (==0.2.0) ; extra == 'all'
Requires-Dist: twine ; extra == 'all'
Requires-Dist: black ; extra == 'all'
Requires-Dist: setuptools ; extra == 'all'
Requires-Dist: gitpython (>=2.0.2) ; extra == 'all'
Requires-Dist: sphinx ; extra == 'all'
Requires-Dist: sphinx-click ; extra == 'all'
Requires-Dist: sphinx-rtd-theme ; extra == 'all'
Requires-Dist: sphinxcontrib-fulltoc ; extra == 'all'
Requires-Dist: pytest (==4.1.0) ; extra == 'all'
Requires-Dist: pytest-cov (==2.7.1) ; extra == 'all'
Requires-Dist: snapshottest (==0.5.0) ; extra == 'all'
Requires-Dist: mock (==2.0.0) ; extra == 'all'
Requires-Dist: tox (==3.12.1) ; extra == 'all'
Requires-Dist: coverage (>=4.4) ; extra == 'all'
Requires-Dist: codecov ; extra == 'all'
Requires-Dist: imageio (>=2.5.0) ; extra == 'all'
Requires-Dist: opencv-python ; extra == 'all'
Requires-Dist: Werkzeug ; extra == 'all'
Requires-Dist: torch ; extra == 'all'
Requires-Dist: torchvision ; extra == 'all'
Requires-Dist: tensorflow ; extra == 'all'
Provides-Extra: api_server
Requires-Dist: gunicorn ; extra == 'api_server'
Requires-Dist: prometheus-client ; extra == 'api_server'
Requires-Dist: Werkzeug ; extra == 'api_server'
Provides-Extra: dev
Requires-Dist: pylint (==2.3.1) ; extra == 'dev'
Requires-Dist: flake8 ; extra == 'dev'
Requires-Dist: tox-conda (==0.2.0) ; extra == 'dev'
Requires-Dist: twine ; extra == 'dev'
Requires-Dist: black ; extra == 'dev'
Requires-Dist: setuptools ; extra == 'dev'
Requires-Dist: gitpython (>=2.0.2) ; extra == 'dev'
Requires-Dist: sphinx ; extra == 'dev'
Requires-Dist: sphinx-click ; extra == 'dev'
Requires-Dist: sphinx-rtd-theme ; extra == 'dev'
Requires-Dist: sphinxcontrib-fulltoc ; extra == 'dev'
Requires-Dist: pytest (==4.1.0) ; extra == 'dev'
Requires-Dist: pytest-cov (==2.7.1) ; extra == 'dev'
Requires-Dist: snapshottest (==0.5.0) ; extra == 'dev'
Requires-Dist: mock (==2.0.0) ; extra == 'dev'
Requires-Dist: tox (==3.12.1) ; extra == 'dev'
Requires-Dist: coverage (>=4.4) ; extra == 'dev'
Requires-Dist: codecov ; extra == 'dev'
Requires-Dist: imageio (>=2.5.0) ; extra == 'dev'
Requires-Dist: opencv-python ; extra == 'dev'
Provides-Extra: imageio
Requires-Dist: imageio (>=2.5.0) ; extra == 'imageio'
Provides-Extra: pytorch
Requires-Dist: torch ; extra == 'pytorch'
Requires-Dist: torchvision ; extra == 'pytorch'
Provides-Extra: tensorflow
Requires-Dist: tensorflow ; extra == 'tensorflow'
Provides-Extra: test
Requires-Dist: pytest (==4.1.0) ; extra == 'test'
Requires-Dist: pytest-cov (==2.7.1) ; extra == 'test'
Requires-Dist: snapshottest (==0.5.0) ; extra == 'test'
Requires-Dist: mock (==2.0.0) ; extra == 'test'
Requires-Dist: tox (==3.12.1) ; extra == 'test'
Requires-Dist: coverage (>=4.4) ; extra == 'test'
Requires-Dist: codecov ; extra == 'test'
Requires-Dist: imageio (>=2.5.0) ; extra == 'test'
Requires-Dist: opencv-python ; extra == 'test'

# BentoML
> From a model in jupyter notebook to production API service in 5 minutes.

[![project status](https://www.repostatus.org/badges/latest/active.svg)](http://bentoml.ai/)
[![build status](https://travis-ci.org/bentoml/BentoML.svg?branch=master)](https://travis-ci.org/bentoml/BentoML)
[![Documentation Status](https://readthedocs.org/projects/bentoml/badge/?version=latest)](https://bentoml.readthedocs.io/en/latest/?badge=latest)
[![pypi status](https://img.shields.io/pypi/v/bentoml.svg)](https://pypi.org/project/BentoML)
[![python versions](https://img.shields.io/pypi/pyversions/bentoml.svg)](https://travis-ci.org/bentoml/BentoML)
[![Downloads](https://pepy.tech/badge/bentoml)](https://pepy.tech/project/bentoml)


BentoML is a python framework for building, shipping and running machine learning
services. It provides high-level APIs for defining an ML service and packaging
its artifacts, source code, dependencies, and configurations into a
production-system-friendly format that is ready for deployment.


[![Google Colab Badge](https://badgen.net/badge/Launch%20Quick%20Start%20Guide/on%20Google%20Colab/blue?icon=terminal)](http://bit.ly/2ID50XP)


---

- [Installation](#installation)
- [Getting Started](#getting-started)
- [Documentation](#documentation)
- [Examples](#examples)
- [Releases and Contributing](#releases-and-contributing)
- [License](#license)


## Feature Highlights

* __Multiple Distribution Format__ - Easily package your Machine Learning models
  and preprocessing code into a format that works best with your inference scenario:
  * Docker Image - deploy as containers running REST API Server
  * PyPI Package - integrate into your python applications seamlessly
  * CLI tool - put your model into Airflow DAG or CI/CD pipeline
  * Spark UDF - run batch serving on a large dataset with Spark
  * Serverless Function - host your model on serverless platforms such as AWS Lambda

* __Multiple Framework Support__ - BentoML supports a wide range of ML frameworks
  out-of-the-box including [Tensorflow](https://github.com/tensorflow/tensorflow/),
  [PyTorch](https://github.com/pytorch/pytorch),
  [Scikit-Learn](https://github.com/scikit-learn/scikit-learn),
  [xgboost](https://github.com/dmlc/xgboost) and can be easily extended to work
  with new or custom frameworks.

* __Deploy Anywhere__ - BentoML bundled ML service can be easily deployed with
  platforms such as [Docker](https://www.docker.com/),
  [Kubernetes](https://kubernetes.io/),
  [Serverless](https://github.com/serverless/serverless),
  [Airflow](https://airflow.apache.org) and [Clipper](http://clipper.ai),
  on cloud platforms including AWS, Gogole Cloud, and Azure.

* __Custom Runtime Backend__ - Easily integrate your python pre-processing code with
  high-performance deep learning runtime backend, such as
  [tensorflow-serving](https://github.com/tensorflow/serving).


## Installation

![python versions](https://img.shields.io/pypi/pyversions/bentoml.svg)
![pypi status](https://img.shields.io/pypi/v/bentoml.svg)

```python
pip install bentoml
```

Verify installation:

```bash
bentoml --version
```


## Getting Started

Defining a machine learning service with BentoML is as simple as a few lines of code:

```python
@artifacts([PickleArtifact('model')])
@env(conda_pip_dependencies=["scikit-learn"])
class IrisClassifier(BentoService):

    @api(DataframeHandler)
    def predict(self, df):
        return self.artifacts.model.predict(df)
```

Read our 5-mins [Quick Start Guide](http://bit.ly/2ID50XP),
showcasing how to productionize a scikit-learn model and deploy it to AWS Lambda.


## Documentation

Official BentoML documentation can be found at [bentoml.readthedocs.io](http://bentoml.readthedocs.io)


## Examples

All examples can be found under the
[BentoML/examples](https://github.com/bentoml/BentoML/tree/master/examples)
directory. More tutorials and examples coming soon!

- [![Google Colab Badge](https://colab.research.google.com/assets/colab-badge.svg)](http://bit.ly/2ID50XP) - [Quick Start Guide](https://github.com/bentoml/BentoML/blob/master/examples/quick-start/bentoml-quick-start-guide.ipynb)
- [![Google Colab Badge](https://colab.research.google.com/assets/colab-badge.svg)](http://bit.ly/2KegK6n) - [Scikit-learn Sentiment Analysis](https://github.com/bentoml/BentoML/blob/master/examples/sklearn-sentiment-clf/sklearn-sentiment-clf.ipynb)
- [![Google Colab Badge](https://colab.research.google.com/assets/colab-badge.svg)](http://bit.ly/2KdwNRN) - [H2O Classification](https://github.com/bentoml/BentoML/blob/master/examples/h2o-classification/h2o-classification.ipynb)
- [![Google Colab Badge](https://colab.research.google.com/assets/colab-badge.svg)](http://bit.ly/2IbtfNO) - [Keras Text Classification](https://github.com/bentoml/BentoML/blob/master/examples/tf-keras-text-classification/tf-keras-text-classification.ipynb)
- [![Google Colab Badge](https://colab.research.google.com/assets/colab-badge.svg)](http://bit.ly/2wPh3M3) - [XGBoost Titanic Survival Prediction](https://github.com/bentoml/BentoML/blob/master/examples/xgboost-predict-titanic-survival/XGBoost-titanic-survival-prediction.ipynb)
- [(WIP) PyTorch Fashion MNIST classification](https://github.com/bentoml/BentoML/blob/master/examples/pytorch-fashion-mnist/pytorch-fashion-mnist.ipynb)
- [(WIP) Tensorflow Keras Fashion MNIST classification](https://github.com/bentoml/BentoML/blob/master/examples/tf-keras-fashion-mnist/tf-keras-fashion-mnist-classification.ipynb)


Deployment guides:
- [Serverless deployment with AWS Lambda](https://github.com/bentoml/BentoML/blob/master/examples/deploy-with-serverless)
- [API server deployment with AWS SageMaker](https://github.com/bentoml/BentoML/blob/master/examples/deploy-with-sagemaker)
- [(WIP) API server deployment on Kubernetes](https://github.com/bentoml/BentoML/tree/master/examples/deploy-with-kubernetes)
- [(WIP) API server deployment with Clipper](https://github.com/bentoml/BentoML/pull/151)


We collect example notebook page views to help us improve this project.
To opt-out of tracking, delete the `[Impression]` line in the first markdown cell of any example notebook: ~~!\[Impression\]\(http...~~


## Releases and Contributing

BentoML is under active development and is evolving rapidly. **Currently it is a
Beta release, we may change APIs in future releases**.

To make sure you have a pleasant experience, please read the [code of conduct](https://github.com/bentoml/BentoML/blob/master/CODE_OF_CONDUCT.md).
It outlines core values and beliefs and will make working together a happier experience.

Have questions or feedback? Post a [new github issue](https://github.com/bentoml/BentoML/issues/new/choose)
or join our gitter chat room: [![join the chat at https://gitter.im/bentoml/BentoML](https://badges.gitter.im/bentoml/BentoML.svg)](https://gitter.im/bentoml/BentoML?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)

Want to help build BentoML? Check out our
[contributing guide](https://github.com/bentoml/BentoML/blob/master/CONTRIBUTING.md) and the
[development guide](https://github.com/bentoml/BentoML/blob/master/DEVELOPMENT.md)
for setting up local development and testing environments for BentoML.

Happy hacking!


## License

BentoML is under Apache License 2.0, as found in the LICENSE file.


[![FOSSA Status](https://app.fossa.io/api/projects/git%2Bgithub.com%2Fbentoml%2FBentoML.svg?type=large)](https://app.fossa.io/projects/git%2Bgithub.com%2Fbentoml%2FBentoML?ref=badge_large)


